# Agente IA para Consultas de EPM ğŸ’§

Este proyecto es una soluciÃ³n de inteligencia artificial diseÃ±ada para responder preguntas de los usuarios sobre las interrupciones del servicio de agua de EPM y otras consultas generales, utilizando informaciÃ³n en tiempo real y una base de conocimiento documental.

## ğŸ¯ Problema

La informaciÃ³n sobre las interrupciones del servicio de agua publicada en el sitio web de EPM, aunque disponible, no es fÃ¡cil de filtrar o consultar. Esto obliga a los usuarios a revisar manualmente largas listas, generando confusiÃ³n y llamadas innecesarias al servicio de atenciÃ³n al cliente.

## âœ¨ SoluciÃ³n

Se ha desarrollado un agente conversacional que utiliza un Modelo de Lenguaje Grande (LLM) para:

1. **Extraer y procesar** la informaciÃ³n actualizada de la pÃ¡gina de EPM en tiempo real.
2. **Consultar una base de conocimiento** con guÃ­as y documentos internos para responder preguntas frecuentes.
3. **Entender y responder** preguntas formuladas en lenguaje natural, proporcionando respuestas claras, rÃ¡pidas y contextualizadas.

---

## ğŸš€ CaracterÃ­sticas Principales

- **Scraping en Tiempo Real**: El agente consulta la pÃ¡gina oficial de EPM al momento de la pregunta para obtener los datos mÃ¡s recientes sobre cortes de agua.
- **Filtrado Inteligente**: Filtra automÃ¡ticamente las interrupciones pasadas para mostrar solo los eventos programados desde el dÃ­a actual en adelante.
- **Base de Conocimiento (RAG)**: Utiliza Retrieval-Augmented Generation para responder preguntas que no estÃ¡n relacionadas con los cortes de agua, basÃ¡ndose en una colecciÃ³n de documentos PDF.
- **Memoria Conversacional**: El agente recuerda el historial de la conversaciÃ³n actual, permitiendo preguntas de seguimiento y un diÃ¡logo mÃ¡s natural.
- **Interfaz de Usuario Amigable**: Incluye una aplicaciÃ³n web creada con Streamlit para una interacciÃ³n fÃ¡cil e intuitiva.
- **API Robusta**: Cuenta con un backend de FastAPI para poder integrar el agente con otros sistemas.

---

## ğŸ—ï¸ Arquitectura del Sistema

El flujo de trabajo de la aplicaciÃ³n sigue la siguiente arquitectura:

```
Usuario
   â”‚
   â–¼
[Interfaz de Usuario (Streamlit) / API (FastAPI)]
   â”‚
   â–¼
[Agente de LangChain con Memoria]
   â”œâ”€â”€> [Herramienta 1: Web Scraper] â†’ (Consulta pÃ¡gina de EPM)
   â”œâ”€â”€> [Herramienta 2: Buscador RAG] â†’ (Consulta Vector Store - FAISS)
   â”‚
   â–¼
[LLM (OpenAI GPT-4o)] â†’ (Genera la respuesta con el contexto obtenido)
   â”‚
   â–¼
Respuesta al Usuario
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Lenguaje**: ğŸ Python 3.11+
- **OrquestaciÃ³n de IA**: ğŸ”— LangChain
- **Modelo de Lenguaje**: ğŸ¤– OpenAI (GPT-4o)
- **Embeddings & Vector Store**: ğŸ§  OpenAI Embeddings & FAISS
- **Web Scraping**: ğŸ² Beautiful Soup
- **Interfaz de Usuario**: ğŸˆ Streamlit
- **Backend API**: ğŸš€ FastAPI
- **GestiÃ³n de Entorno**: ğŸ“¦ venv, python-dotenv

---

## âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n

Sigue estos pasos para poner en marcha el proyecto en tu mÃ¡quina local.

### 1. Clonar el Repositorio

```bash
git clone <URL_DEL_REPOSITORIO>
cd epm-agents
```

### 2. Crear y Activar el Entorno Virtual

```bash
# Crear el entorno
python -m venv venv

# Activar en Windows
.\venv\Scripts\activate

# Activar en macOS/Linux
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Variables de Entorno

Crea un archivo llamado `.env` en la raÃ­z del proyecto.  
Puedes copiar el contenido de `.env.example` (si existe) o aÃ±adir la siguiente lÃ­nea:

```bash
# .env
OPENAI_API_KEY="sk-..."
```

Reemplaza `sk-...` con tu clave de API de OpenAI.

### 5. Preparar la Base de Conocimiento (RAG)

Coloca todos los documentos PDF de las guÃ­as de EPM dentro de la carpeta `docs/`.

Ejecuta el script de ingestiÃ³n para procesar los documentos y crear la base de datos vectorial:

```bash
python -m src.rag.ingest_rag_data
```

Este comando crearÃ¡ una carpeta `faiss_index` en la raÃ­z del proyecto.

---

## â–¶ï¸ CÃ³mo Ejecutar la AplicaciÃ³n

Tienes dos formas de interactuar con el agente:

### 1. A travÃ©s de la Interfaz de Usuario (Recomendado)

Ejecuta la aplicaciÃ³n de Streamlit con el siguiente comando:

```bash
streamlit run ui.py
```

Abre tu navegador y ve a: [http://localhost:8501](http://localhost:8501)

### 2. A travÃ©s de la API

Ejecuta el servidor de FastAPI:

```bash
uvicorn src.api.main:app --reload
```

Abre tu navegador y ve a: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)  
para acceder a la documentaciÃ³n interactiva de la API y hacer pruebas.

---

## ğŸ“ Estructura del Proyecto

```bash
epm-agents/
â”œâ”€â”€ .env                  # Archivo de secretos (API Keys) - NO SUBIR A GIT
â”œâ”€â”€ .gitignore            # Archivos a ignorar por Git
â”œâ”€â”€ requirements.txt      # Dependencias de Python
â”œâ”€â”€ ui.py                 # Interfaz de usuario con Streamlit
â”œâ”€â”€ docs/                 # Carpeta para los PDFs de las guÃ­as (RAG)
â””â”€â”€ src/
    â”œâ”€â”€ agent/            # LÃ³gica del agente de LangChain
    â”‚   â”œâ”€â”€ agent_creator.py
    â”‚   â””â”€â”€ tools.py
    â”œâ”€â”€ api/              # Backend con FastAPI
    â”‚   â””â”€â”€ main.py
    â”œâ”€â”€ core/             # ConfiguraciÃ³n central
    â”‚   â””â”€â”€ config.py
    â”œâ”€â”€ rag/              # LÃ³gica para RAG
    â”‚   â””â”€â”€ ingest_rag_data.py
    â””â”€â”€ scraping/         # LÃ³gica de Web Scraping
        â”œâ”€â”€ scraper.py
        â””â”€â”€ parser.py
```
